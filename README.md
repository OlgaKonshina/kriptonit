# Проектный практикум III.(Криптонит). Команда 22.
### Члены команды:
* Дмитрий Шабанов - лидер
* Коньшина Ольга
* Прохорова Екатарина
* Ильиных Виктория
* Татьяна Егоренкова
* Василий Воробьев

### Задача
Обучить языковую модель для классификации эмоций в текстах на русском языке. Количество эмоций - 7, при этом текст может иметь не одну эмоцию, а несколько.
###  Этапы выполнения проекта.
#### Разведочный анализ данных.
Особенности выявленные в предоставленных данных:
* В данных  в данных присутствует дисбаланс классов. Явное преобладание класса 'joy'. Недостаточно представлены классы 'disgust', 'fear'.
* Значительная часть данных — результат машинного перевода с английского языка, что отражается на стиле изложения и лексике.
* Присутствует значимая неточность в разметке, когда представленный класс явно не соответствует контексту.
* Значительная часть текстовых данных содержит ошибки/опечатки,
* Отсутствует/нарушена пунктуация

#### Добавление данных в обучающий набор.
* Добавление данных с помощью модели rut5-base-paraphraser. Идея заключается в том, чтобы добавить тексты в мало представленные классы с помощью перефразирования с сохранением меток.
  Скрипт - adding data/perephras.py
* Добавление данных из датасета CEDR. CEDR - Корпус для выявления эмоций в предложениях русскоязычных текстов из разных социальных источников содержит 9410 комментариев, помеченных по 5 категориям эмоций (радость, грусть, удивление, страх и гнев). Скрипт - adding data/perephras.py
  В настоящим момент проводится работа с устранением дисбаланса отдельных классов.
  
#### Предобработка данных.
* Выполнены стандартные этапы очистки данных (удаление знаков препинания, удаление emoji, сторонних символов, приведение к нижнему регистру).
* Выполнено удаление стоп слов, лемматизации. Эти этапы обраброки снижают качество обчения модели.
* Выполнено удаление редковстречаемых слов. Скрипт - data preparation/clean_data.ipynb
  
#### Обучение модели.
Было рассмотрено несколько потенциальных вариантов архитектуры:
* Было обучено несколько моделей, основанных на архитектуре BERT(ruBert-base, rudert-tyny2), с различными наборами гиперпараметров. Наилучшие результаты были получены с использованием модели ruBert-base и оптимизатора AdamW.(F1 weighted на тестовых данных 0.56). Добавление дополнительных данных и использование сложной предварительной обработки ухудшают качество модели.
* Рассматривается вариант обучения нескольких отдельных логистических регрессий под предсказания вероятности отнесения текста к каждому классу. Возможно потребуется решить задачу установки минимальных пороговых ограничений по привязке конкретного класса к тексту
